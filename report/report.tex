\def\year{2018}\relax
%Taken from file: formatting-instruction.tex
\documentclass[letterpaper]{article} %DO NOT CHANGE THIS
\usepackage{aaai18}  %Required
\usepackage{times}  %Required
\usepackage{helvet}  %Required
\usepackage{courier}  %Required
\usepackage{url}  %Required
\usepackage{graphicx}  %Required
\frenchspacing  %Required
\setlength{\pdfpagewidth}{8.5in}  %Required
\setlength{\pdfpageheight}{11in}  %Required
%PDF Info Is Required:
%   \pdfinfo{
% /Title (Removing Viruses with Machine Learning in Dr.~Mario)
% /Author (Ryan Gately and JJ Brown)}

\usepackage{natbib}
\usepackage{url}

\author{Ryan Gately and JJ Brown}
\date{\today}
\title{Removing Viruses with Machine Learning in Dr.~Mario}

\bibliographystyle{aaai}

\renewcommand{\citet}[1]{\citeauthor{#1}~\shortcite{#1}}
\renewcommand{\citep}{\cite}
\renewcommand{\citealp}[1]{\citeauthor{#1}~\citeyear{#1}}

\begin{document}

\maketitle

\begin{abstract}
We trained machine learning agents that manipulate an NES controller to play Dr.~Mario by~\cite{drmario90}, using the FCEUX emulator by~\cite{fceux18}.
Both Q-learning and SARSA learning algorithms showed some advantage over a random controller.
We compared a SARSA agent that viewed the local ``neighborhood'' around the player's capsule and controlled the controller directly to a Q-learning agent that viewed the entire topmost layer of viruses and executed high-level actions in the game. Ultimately, while we believe the local ``neighborhood'' state space may allow for the highest theoretical quality of performance, the Q-learning agent with a high-level controller yielded the best results, with the fastest rate of learning and the highest average performance.
\end{abstract}

\section{Introduction}
Video games are an interesting application for developing machine learning agents beacuse the strictly-defined playing space provides a clean, simple environment for learning. Furthermore, they are also interesting such that they challenge the player to develop an effective strategy. We researchers, then, seek to determine whether a machine learning agent, using a simple learning algorithm, can effectively develop such strategies as to ``beat'' those games on par with a human, or if the game requires such skill as to mandate a human player.

We selected the classic video game ``Dr.~Mario'' by~\cite{drmario90} as the best candidate to develop a machine learning agent for, because we believed the simple yet challenging puzzle of dropping colored capsules would be viable for a machine learning agent to solve, yet difficult enough to force the agent to develop an effective strategy for winning.


\section{Problem Definition and Approaches}
\subsection{Task Definition}

\subsection{Algorithm Definition}

\section{Experimental Evaluation}
\subsection{Methodology}

\subsection{Results}

\subsection{Discussion}

\section{Related Work}

\section{Future Work}
In the future, we think we could improve the efficacy of the learning algorithms by rewarding agents for accomplishing sub-goals as discussed in~\cite{banzas15} and~\cite{bhonker17}, such as rewarding the agent for matching smaller numbers of matching colors or for matching a series of only capsule blocks (which the game does not reward), rather than only rewarding it for making matches that include colored virus blocks.

\section{Conclusion}

\newpage
\section{Bibliography}

\bibliography{report}

\end{document}